{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nodes 2020 Talk: Network Like an Egghead**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook examines a linkedin personal network via a python interface with a Neo4j Desktop Environment, which includes a graph database. \n",
    "\n",
    "Due to the inclusion of personal information, I will not share the data directly, but will by happy to answer questions about it so that the results can be reproduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase # The neo4j driver for python; allows interface with Neo4j \n",
    "import pandas as pd # Data inspection and Manipulation\n",
    "import pickle # Data serialization\n",
    "from py2neo import Graph # Allows easier neo4j database & graph commands/queries w/ python\n",
    "from py2neo import Node, Relationship, NodeMatcher\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish bolt connection to database. Make sure database is started from Neo4j Desktop!\n",
    "\n",
    "url = \"bolt://localhost:7687\"\n",
    "graph_3 = Graph(url, auth=(\"neo4j\", \"testy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_3.nodes), len(graph_3.relationships) # Check the nodes and links in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_3.delete_all() # In case you need to delete the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newnewdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import csv data\n",
    "- \"data_for_common_nodes\": a table of my 'nodes'; each row is a linkedin 1st order contact\n",
    "- \"mutual connections\": a python dictionary of my mutual connections; \n",
    "                        Each key is a direct contact\n",
    "                        Each value is a list of mutual contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct, 1st order nodes\n",
    "df = pd.read_csv('data_for_common_nodes_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual Connections between 1st order nodes\n",
    "# Collected and cleaned, and placed in serialized (pickled) file\n",
    "filename = 'mutual_connections'\n",
    "infile = open(filename,'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionarys to convert between profile urls and profile IDs\n",
    "url_to_id = dict(zip(df.linkedinProfile,df.profileId))\n",
    "id_to_url = dict(zip(df.profileId,df.linkedinProfile))\n",
    "id_to_title = dict(zip(df.profileId,df.jobTitle))\n",
    "url_to_title = dict(zip(df.linkedinProfile,df.jobTitle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines are meant for cleanup. Since the nodes from the two sources above \n",
    "# were collected at different times, the may be inconsistent. \n",
    "# This uses the nodes drawn from the mutual connections files as the 'master' set.\n",
    "# It also eliminates nans, zeros, and nulls if they exist\n",
    "\n",
    "node_list = new_dict.keys()  # \n",
    "list_of_node_lists = [id_to_url[x] for x in list(node_list) if x != 0]\n",
    "\n",
    "for k,v in new_dict.items():\n",
    "    trimmed_v = [x for x in v if x in list_of_node_lists] \n",
    "    new_dict[k] = trimmed_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate the dictionary of mutual connections. In the mutual connections dictionary, \n",
    "# mirrored relationships exist. E.g., x-->y and y-->x are represented. Since my interpretation\n",
    "# is an undirectly graph, one of these relationships is superflous. This quick and dirty \n",
    "# code simply loops through the mutual connections to create a new dictionary. If it finds\n",
    "# superfluous connections, it eliminates them.\n",
    "\n",
    "newnewdict={}\n",
    "for k,v in new_dict.items():\n",
    "    newnewdict[k]=[]\n",
    "    newlist=[]\n",
    "    for val in v:\n",
    "        \n",
    "        if url_to_id[val] in newnewdict:\n",
    "        \n",
    "            try:\n",
    "                if (id_to_url[k] in new_dict[url_to_id[val]]) and (id_to_url[k] in newnewdict[url_to_id[val]]):\n",
    "                    continue\n",
    "                elif (id_to_url[k] in new_dict[url_to_id[val]]) and not (id_to_url[k] in newnewdict[url_to_id[val]]):\n",
    "                    newlist.append(val)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        else:\n",
    "            newlist.append(val)          \n",
    "        \n",
    "    newnewdict[k]=newlist  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many 1st order LinkedIn Connections\n",
    "\n",
    "len(set(list_of_node_lists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node and Edge Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nodes, than Edges for Direct Connections\n",
    "\n",
    "# First create the 'central' node (the linkedin account owner)\n",
    "\n",
    "me = 'Keita Broadwater'\n",
    "\n",
    "me = Node('Person', name='Keita Broadwater', title='ML Eng') # creates a node object of type \"Person\"\n",
    "                                             # using the attributes 'name' and 'title'\n",
    "graph_3.create(me) # Creates a node in the Neo4j database\n",
    "\n",
    "\n",
    "# This code loops through the set of nodes, \n",
    "# first, creating the node in the Neo4j database,\n",
    "# then, creating the edge between the 'central' node (me) and that 1st order node\n",
    "\n",
    "for node in list(set(list_of_node_lists)):\n",
    "    try:\n",
    "        idd= url_to_id[node]\n",
    "        titl= url_to_title[node]\n",
    "        you = Node('Person', name=idd, title=titl) # assigns a node object to the variable 'you'\n",
    "        graph_3.create(you) # create the node in Neo4j\n",
    "        graph_3.create(Relationship(me, \"knows\", you)) # creates the edge of type 'knows' \n",
    "                                                       # in Neo4j\n",
    "    except: continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Edges for mutual connections\n",
    "\n",
    "for k,v in newnewdict.items(): # 'k' is the node under consideration\n",
    "                             # 'v' is the list of mutually connected nodes of 'k'\n",
    "    \n",
    "    \n",
    "    # The next 3 lines do cleanup of zero items, and items that are not in master list.\n",
    "    if k==0: continue # Some items in original were zero. This line eliminates them.\n",
    "    uk = id_to_url[k] # convert id to URL, to match to master list.  \n",
    "    if uk not in list_of_node_lists:continue\n",
    "    \n",
    "    # This cycles through the mutual connections, and creates their edges\n",
    "    for node in v:\n",
    "        \n",
    "        if node not in list_of_node_lists:continue # must be in master list\n",
    "        if node != '': # must not have blank value\n",
    "            \n",
    "            nodeu = url_to_id[node] # converts to ID\n",
    "            \n",
    "            # Next two lines create python objects from the Neo4j node objects\n",
    "            # Then these objects are used to create a mutual edge in the third line\n",
    "            existing_u1 = graph_3.evaluate('MATCH (x) WHERE x.name=\"{}\" RETURN(x)'.format(k))\n",
    "            existing_u2 = graph_3.evaluate('MATCH (x) WHERE x.name=\"{}\" RETURN(x)'.format(nodeu)) \n",
    "            graph_3.create(Relationship(existing_u1, \"knows\", existing_u2))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep data for Export to Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4018</td>\n",
       "      <td>ML Eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4019</td>\n",
       "      <td>CTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4021</td>\n",
       "      <td>General Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4022</td>\n",
       "      <td>Founder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id            Title\n",
       "0  4018           ML Eng\n",
       "1  4019              CTO\n",
       "2  4020              NaN\n",
       "3  4021  General Manager\n",
       "4  4022          Founder"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cypher to create Node Table for export to Gephi\n",
    "cypher_all_nodes=\"MATCH (n) RETURN id(n),n.title \"\n",
    "nodes_df = graph_3.run(cypher_all_nodes).to_data_frame()\n",
    "nodes_df.columns =['Id', 'Title'] \n",
    "nodes_df.to_csv('nodes_for_gephi.csv')\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5726</td>\n",
       "      <td>4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5085</td>\n",
       "      <td>4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4018</td>\n",
       "      <td>4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4018</td>\n",
       "      <td>4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4398</td>\n",
       "      <td>4021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target\n",
       "0    5726    4019\n",
       "1    5085    4019\n",
       "2    4018    4019\n",
       "3    4018    4020\n",
       "4    4398    4021"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cypher to create Edge Table for export to Gephi\n",
    "cypher_all_edges=\"MATCH (n)-[r]->(m) RETURN id(n),id(m)\"\n",
    "edges_df = graph_3.run(cypher_all_edges).to_data_frame()\n",
    "edges_df.columns =['Source', 'Target'] \n",
    "edges_df.to_csv('edges_for_gephi.csv')\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells are not meant to be run in order, since some of them modify the database. Some of the query results are best viewed by running the queries directly in the Neo4j interface. Some are best viewed by collecting the results in pandas dataframes and visualizing in the notebook. Or by exporting the query results to Gephi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries for to create and modify graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph object\n",
    "cypher_create_graph = '''CALL gds.graph.create(\n",
    "    'my-linkedin-graph',\n",
    "    'Person',\n",
    "    'knows'\n",
    ")\n",
    "YIELD graphName, nodeCount, relationshipCount, createMillis;'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a node from the graph database\n",
    "cypher_delete_node ='''MATCH (p:Person)\n",
    "WHERE p.name = 'Keita Broadwater'\n",
    "DETACH DELETE  p'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all edges\n",
    "cypher_all_edges=\"MATCH (n)-[r]->(m) RETURN id(n),id(m)\"\n",
    "\n",
    "# Return all nodes\n",
    "cypher_all_nodes=\"MATCH (n) RETURN id(n),n.title \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_component_count='''CALL gds.wcc.stats('my-linkedin-graph')\n",
    "YIELD componentCount, componentDistribution\n",
    "RETURN componentCount, \n",
    "       componentDistribution.min as min,\n",
    "       componentDistribution.max as max,\n",
    "       componentDistribution.mean as mean'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of components and their size\n",
    "cypher_components_list='''CALL gds.wcc.stream('my-linkedin-graph-sans-keita') \n",
    "YIELD nodeId, componentId RETURN componentId, count(*) as size \n",
    "ORDER BY size DESC LIMIT 1000'''\n",
    "\n",
    "\n",
    "cypher_diameter_count_and_show='''MATCH (a:Person), (b:Person) WHERE id(a) > id(b)\n",
    "MATCH path = shortestPath((a)-[:knows*]-(b))\n",
    "RETURN path, length(path) AS len\n",
    "ORDER BY len DESC\n",
    "LIMIT 10'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries for Centrality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree\n",
    "cypher_degree_centrality='''CALL gds.alpha.degree.stream('my-linkedin-graph')\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).title AS title, score\n",
    "ORDER BY score DESC'''\n",
    "\n",
    "# Betweenness\n",
    "cypher_betweenness_centrality='''CALL gds.betweenness.stream('my-linkedin-graph')\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).title AS title, score\n",
    "ORDER BY score DESC'''\n",
    "\n",
    "# PageRank\n",
    "cypher_page_rank='''CALL gds.pageRank.stream('my-linkedin-graph')\n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).title AS title, score\n",
    "ORDER BY score DESC'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries for Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modularity Optimization\n",
    "modularity_opt = '''CALL gds.beta.modularityOptimization.stream('my-linkedin-graph')\n",
    "YIELD nodeId, communityId\n",
    "RETURN gds.util.asNode(nodeId).title AS title, communityId\n",
    "ORDER BY title'''\n",
    "modularity_results_df = graph_3.run(modularity_opt).to_data_frame()\n",
    "modularity_results = nodes_df.merge(modularity_results_df, left_on='Id', right_on='nodeId')\n",
    "modularity_results.to_csv('modopt_nodes_for_gephi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weakly Connected Components\n",
    "wcc = '''CALL gds.wcc.stream('my-linkedin-graph')\n",
    "YIELD nodeId, componentId\n",
    "RETURN nodeId,gds.util.asNode(nodeId).title AS title, componentId\n",
    "ORDER BY nodeId,componentId, title'''\n",
    "wcc_results_df = graph_3.run(wcc).to_data_frame()\n",
    "wcc_results = nodes_df.merge(wcc_results_df, left_on='Id', right_on='nodeId')\n",
    "wcc_results.to_csv('wcc_nodes_for_gephi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K1 Coloring - This assigns differnt colors to adjacent nodes; good as a counterpoint to \n",
    "# community detection\n",
    "k1_detection = '''CALL gds.beta.k1coloring.stream('my-linkedin-graph')\n",
    "YIELD nodeId, color\n",
    "RETURN nodeId,gds.util.asNode(nodeId).title AS title, color\n",
    "ORDER BY nodeId'''\n",
    "k1_results_df = graph_3.run(k1_detection).to_data_frame()\n",
    "k1_results = nodes_df.merge(k1_results_df, left_on='Id', right_on='nodeId')\n",
    "k1_results.to_csv('k1_nodes_for_gephi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K1 Coloring - This assigns differnt colors to adjacent nodes\n",
    "# Same as above, but run on a graph where the 'central' node has been removed. This results\n",
    "# in a few connected components and changes many of the centrality characteristics\n",
    "\n",
    "k1_detection2 = '''CALL gds.beta.k1coloring.stream('my-linkedin-graph-undirected')\n",
    "YIELD nodeId, color\n",
    "RETURN nodeId,gds.util.asNode(nodeId).title AS title, color\n",
    "ORDER BY nodeId'''\n",
    "k1_results_df2 = graph_3.run(k1_detection2).to_data_frame()\n",
    "k1_results2 = nodes_df.merge(k1_results_df2, left_on='Id', right_on='nodeId')\n",
    "k1_results2.to_csv('k1_nodes2_for_gephi.csv') # Node table output. This can be used with the \n",
    "# edge table generated above in a previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Graph Sage to create embeddings, then perform K-means clustering on those embeddings\n",
    "# Finally shaping the results for output as a Node Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_sage = '''CALL gds.alpha.graphSage.stream(\n",
    "  'my-linkedin-graph-undirected',\n",
    "  {\n",
    "    aggregator: 'mean',\n",
    "    activationFunction: 'sigmoid',\n",
    "    embeddingSize: 3,\n",
    "    sampleSizes: [25, 10],\n",
    "    degreeAsProperty: true\n",
    "  }\n",
    ")'''\n",
    "graphsage_results_df = graph_3.run(graph_sage).to_data_frame()\n",
    "graphsage_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = graphsage_results_df.embeddings.to_numpy() # Convert embeddings to numpy array\n",
    "node_ids = graphsage_results_df.nodeId # The node ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[x for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=6, init='k-means++', max_iter=100, n_init=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(node_ids, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(node_ids, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(node_ids, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(node_ids, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_results_df['community'] = list(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_results_nodes = nodes_df.merge(graphsage_results_df, left_on='Id', right_on='nodeId')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_results_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_results_nodes.to_csv('graphsage_nodes_for_gephi.csv') # The node table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df.to_csv('edges_for_gephi.csv') # The edges table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
